{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Phát hiện khuôn mặt\n",
    "face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        print(x,y,w,h)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_frame = frame[y:y+h, x:x+w]\n",
    "        img_item = \"my_image.png\"\n",
    "        img_frame = \"my_frame.png\"\n",
    "        cv2.imwrite(img_item,roi_gray)\n",
    "        cv2.imwrite(img_frame,roi_frame)\n",
    "        # Draw rectangle\n",
    "        \n",
    "        \n",
    "        color = (255,0,0) #BGR 0-255   \n",
    "        stroke = 2\n",
    "        end_cord_x  = x+w\n",
    "        end_cord_y = y +h\n",
    "        cv2.rectangle(frame,(x,y),(end_cord_x,end_cord_y),color,stroke)\n",
    "    # Mirror images \n",
    "    flip_img = cv2.flip(frame,1)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',flip_img)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR\n",
    "image_dir = os.path.join(BASE_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x0000028DF6449580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\tuana\\\\My Folder\\\\AILearn\\\\QuangNinh\\\\GitFaceReconigtion\\\\Example5\\\\data\\\\1_NguyenVanAnh_10A\\\\9.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D:\\tuana\\My Folder\\AILearn\\QuangNinh\\GitFaceReconigtion\\Example5\\data\\1_NguyenVanAnh_10A\\4.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "path = r'D:\\tuana\\My Folder\\AILearn\\QuangNinh\\GitFaceReconigtion\\Example5\\data\\1_NguyenVanAnh_10A\\4.jpg'\n",
    "frame = cv2.imread(path)\n",
    "frame_resize = cv2.resize(frame,(500,500))\n",
    "gray = cv2.cvtColor(frame_resize, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "print(len(faces))\n",
    "for(x,y,w,h) in faces:\n",
    "    print(x,y,w,h)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    img_item = \"my_image_12.png\"\n",
    "    img_frame = \"my_frame_12.png\"\n",
    "    cv2.imwrite(img_item,roi_gray)\n",
    "    cv2.imwrite(img_frame,roi_frame)\n",
    "#     # Draw rectangle\n",
    "    \n",
    "    \n",
    "#     color = (255,0,0) #BGR 0-255   \n",
    "#     stroke = 2\n",
    "#     end_cord_x  = x+w\n",
    "#     end_cord_y = y +h\n",
    "#     cv2.rectangle(frame_resize,(x,y),(end_cord_x,end_cord_y),color,stroke)\n",
    "    # Mirror images \n",
    "# flip_img = cv2.flip(frame,1)\n",
    "cv2.imshow('frame',gray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = r'D:\\tuana\\My Folder\\AILearn\\QuangNinh\\GitFaceReconigtion\\Example5\\data\\1_NguyenVanAnh_10A\\4.jpg'\n",
    "image = Image.open(path)\n",
    "new_image = image.resize((400, 400))\n",
    "new_image.save('image_400.jpg')\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4324b6bac74df9d7fa14492ccb753ee082ee92c087965af295806778d6712027"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
